{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Convolutional Networks are simply neural networks that use convolution in place of general matrix multiplication in at least one of their layers.** ~ Deep Learning Book\n",
    "\n",
    "\n",
    "# 1. The Convolution Operation\n",
    "Convolution is an operation on two functions of a real-valued argument.\n",
    "\n",
    "Examples:\n",
    "- Suppose we are tracking the location of a spaceship with a laser sensor. Our laser Sensor provides a single output $x(t)$, the position of the spaceship at time $t$. Both $x$ and $t$ are real-valued. Now suppose that our laser sensor is somewhat noisy. To obtain a less noisy estimate of the spaceship's position, we would like to average together several measurements. Of course, more recent measurements are more relevant, so we will want this to a weighted average that gives more weight to recent measurements. We can do this with a weighting function $w(a)$. $a$ is the age of a measurement\n",
    "\n",
    "$$s(t) = \\int x(a)w(t-a)da$$\n",
    "\n",
    "This operation is called **convolution**. The convolution operation is typically denoted with an asterisk:\n",
    "\n",
    "$$s(t) = (x*w)(t)$$\n",
    "\n",
    "- $x:$ is the input\n",
    "- $w:$ is the kernel\n",
    "- The output is referred to as the feature map\n",
    "\n",
    "If we assume that $x$ and $w$ are defined only on integer t, we get the discrete convolution:\n",
    "\n",
    "$$s(t) = (x*w)(t) = \\sum_{a=-\\infty }^{\\infty }x(a)w(t-a)$$\n",
    "\n",
    "# 2. Motivation\n",
    "Convolution leverages three important ideas that can help improve a machine learning system:\n",
    "- Sparse interactions\n",
    "- Parameter sharing\n",
    "- Equivariant representations\n",
    "\n",
    "\n",
    "Traditional NN layers use matrix multiplication by a matrix parameters with a separate parameter describing the interaction between each input unit and each output unit. CNN, however, typically have **sparse interactions**. This is accomplished by making the kernel smaller than the input. For example, when processing an image the input image might have thousands or millions of pixels, but we can detect small, meaningful features such as edges with kernels that occupy only tens or hundreds of pixels.\n",
    "\n",
    "Therefore, we can store fewer parameters and reduce memory requirements of the model.\n",
    "\n",
    "**Parameter sharing** refers to using the same parameter for more than one function in a model. In a CNN, each member of the kernels is used at every position of the input(except perhaps some of the boundary pixels, depending on the design decisions regarding the boundary). This reduces the storage requirements of the model to $k$ parameters. \n",
    "\n",
    "\n",
    "In a CNN, the particular form of parameter sharing causes the layer to have a property called **equivariance** to translation. A function is equivariant when the input changes, the output changes the same way. For Example a picture with a kitten in the middle. For a CNN it doesn't matter if the kitten is fed with a picture with a kitten in the corner. It will classify the same kitten as a kitten. \n",
    "\n",
    "**Note:**\n",
    "- Convolution is not naturally equivariant to some other transformations, such as changes in the scale or rotation of an image.\n",
    "\n",
    "# 3. Architecture Overview\n",
    "\n",
    "Convolutional Neural Networks (CNN) take advantage of the fact that the input consists of images and they constrain the architecture in a more sensible way. In particular, unlike a regular Neural Network, the layers a ConVNet have neurons arranged in 3 dimensions: **width, height, depth.**\n",
    "\n",
    "1) ![](assets/neural_net2.jpeg)\n",
    "__________________________________\n",
    "______________________________________\n",
    "2) ![](assets/cnn.jpeg)\n",
    "\n",
    "> 1: A regular 3-layer Neural Network. 2: A ConvNet arranges its neurons in three dimensions (width, height, depth), as visualized in one of the layers. Every layer of a ConvNet transforms the 3D input volume to a 3D output volume of neuron activations. In this example, the red input layer holds the image, so its width and height would be the dimensions of the image, and the depth would be 3 (Red, Green, Blue channels).\n",
    "\n",
    "\n",
    "# 4. Layers used to build ConvNets\n",
    "A simple ConvNet is a sequence of layers, and every layer of a ConvNet transforms one volume of activations to another through \n",
    "a differentiable function. \n",
    "\n",
    "Three main types of layers to build ConvNet architectures:\n",
    "- **Convolutional Layer**\n",
    "- **Pooling Layer**\n",
    "- **Fully-Connected Layer**\n",
    "\n",
    "*Example Architecture:*\n",
    "\n",
    "A simple ConvNet for [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) Classification could have the architecture \n",
    "**[INPUT - CONV - RELU - POOL - FC].**\n",
    "\n",
    "- INPUT[32x32x3] will hold the raw pixel values of the image, in this case an image of width 32, height 32, and with three color channels R, G, B.\n",
    "- CONV layer will compute the output of neurons that are connected to local regions in the input, each computing a dot product between their weights and a small region they are connected to in the input volume. This may result in volume such as [32x32x12] if we decided to use 12 filters. (Filters are explained in later paragraph)\n",
    "- RELU layer will apply an elementwise activation function, such as the $max(0,x)$ thresholding at zero. This leaves the size of the volume unchanged([32x32x12]).\n",
    "- POOL layer will perform a downsampling operation along the spatial dimensions (width, height), resulting in volume such as [16x16x12].\n",
    "- FC(full-connected) layer will compute the class scores, resulting in volume of size ([1x1x10]), where each of the 10 numbers correspond to a class score, such as among the 10 categories of  [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html).\n",
    "\n",
    "Notice that some layers contain parameters and other don't. In particular, the CONV/FC layers perform transformations that are a function of not only the activations in the input volume, but also of the parameters (the weights and biases of the neurons).\n",
    "\n",
    "On the other hand, RELU/POOL layers will implement a fixed function. The parameters in the CONV/FC layers will be trained with gradient descent so that the class scores that the ConvNet computes are consistent with the labels in the training set for each image.\n",
    "\n",
    "In summary:\n",
    "\n",
    "\n",
    "- A ConvNet architecture is in the simplest case a list of Layers that transform the image volume into an output volume (e.g. holding the class scores)\n",
    "- There are a few distinct types of Layers (e.g. CONV/FC/RELU/POOL are by far the most popular)\n",
    "- Each Layer accepts an input 3D volume and transforms it to an output 3D volume through a differentiable function\n",
    "- Each Layer may or may not have parameters (e.g. CONV/FC do, RELU/POOL don’t)\n",
    "- Each Layer may or may not have additional hyperparameters (e.g. CONV/FC/POOL do, RELU doesn’t)\n",
    "\n",
    "![](assets/convnet.jpeg)\n",
    "\n",
    "# 5. Convolutional Layer\n",
    "The Convolutional layer is the core building block of a ConvNet that does most of the computational heavy lifting.\n",
    "\n",
    "The CONV layer's parameters consist of a set of learnable filters. Every filter \n",
    "\n",
    "# Pooling\n",
    "![](assets/pooling.jpg)\n",
    "\n",
    "A typical layer of a convolutional network consists of three stages. \n",
    "- In the first layer, the layer performs several convolutions in parallel to produce a set of linear activations. \n",
    "- In the second layer, each linear activation is run through a non linear activation function, such as the rectified linear activation function. This stage is sometimes called **the detector stage**. \n",
    "- In the third stage, we use a **pooling function** to modify the output of the layer further.\n",
    "\n",
    "A pooling function replaces the output of the net at a certain location with a summary statistic of the nearby outputs. For example, the *max pooling* operation reports the maximum output within a rectangular neighborhood. \n",
    "\n",
    "Pooling helps to make the representation become approximately *invariant* to small translations of the input. Invariance to translation means that if we translate the input by a small amount, the values of most of the pooled outputs do not change.\n",
    "\n",
    "Because pooling summarizes the responses over a whole neighborhood, it is possible to use fewer pooling units than detector units, by reporting summary statistics for pooling regions spaced $k$ pixels rather than $1$ pixel apart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
